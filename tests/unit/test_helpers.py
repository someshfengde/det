# Generated by CodiumAI
import pytest
from unittest.mock import Mock, patch

from det.embeddings.adapters import AnotherEmbeddingGeneratorAdapter
from det.helpers import (
    _get_client_class,
    get_embedding_generator_adapter,
    get_llm_client,
)
from det.llm.llm_openai import OpenAIClient


@pytest.fixture
def mock_openai_client(mocker):
    # Patch the OpenAI class to return a mock instance instead of a real one
    with patch("det.llm.llm_openai.OpenAI") as MockOpenAI:
        # Create a mock OpenAI client instance
        mock_openai_instance = Mock()
        # Configure the mock OpenAI class to return the mock instance
        MockOpenAI.return_value = mock_openai_instance

        # Now, when OpenAIClient is instantiated, it will use the mocked OpenAI client
        client = OpenAIClient(model="gpt-3.5-turbo")

        # Return both the mock OpenAI instance and the OpenAIClient instance
        # This allows tests to interact with and make assertions about the mock OpenAI client
        return mock_openai_instance, client


def test_openai_client_initialization(mock_openai_client):
    # mock_openai_client fixture returns a tuple, so we unpack it
    mock_openai_instance, openai_client = mock_openai_client

    # Assert that the OpenAIClient has a "client" attribute which is our mock
    assert openai_client.client == mock_openai_instance


@pytest.mark.usefixtures("mock_openai_client")
class Test_GetClientClass:
    # Can import a valid client class from a valid module path and return it
    def test_valid_module_path(self):
        # Arrange
        module_path = "det.llm.llm_openai"
        class_name = "OpenAIClient"

        # Act
        result = _get_client_class(module_path, class_name)

        # Assert
        assert result == OpenAIClient

    # Raises ImportError when the module path is invalid
    def test_invalid_module_path(self):
        # Arrange
        module_path = "det.llm.invalid_module"
        class_name = "ProviderClient"

        # Act and Assert
        with pytest.raises(ImportError):
            _get_client_class(module_path, class_name)

    # Should be able to import the specified client class from the constructed module path and instantiate it with the given model parameter
    def test_import_and_instantiate_client(self):
        llm_provider = "OpenAI"
        llm_model = "gpt-4"

        # Call the function under test
        client = get_llm_client(
            llm_provider=llm_provider, llm_model=llm_model, api_key="testing"
        )

        # Assert that the client is an instance of the imported client class
        assert isinstance(client, OpenAIClient)

        # Assert that the client was instantiated with the correct model parameter
        assert client.model == llm_model

    # llm_provider and llm_model parameters are None
    def test_none_parameters(self):
        llm_provider = None
        llm_model = None

        # Call the function under test
        with pytest.raises(ValueError):
            get_llm_client(llm_provider, llm_model)

    # Raises ImportError when the module path is invalid
    def test_invalid_parameters(self):
        llm_provider = "invalid"
        llm_model = "invlaid"

        # Call the function under test
        with pytest.raises(ImportError):
            get_llm_client(llm_provider, llm_model)

    # Returns an instance of the specified embedding generator adapter class with the specified model name.
    def test_returns_instance_of_embedding_generator_adapter_class(self):
        # Arrange
        embeddings_provider = "Another"
        embeddings_model = "TestModel"

        # Act
        result = get_embedding_generator_adapter(embeddings_provider, embeddings_model)

        # Assert
        assert isinstance(result, AnotherEmbeddingGeneratorAdapter)
        assert result.model == embeddings_model
